# ðŸ‘” Customer Intel Agent â€” CrewAI + Local LLM (FREE)

Interactive agentic demo you can run **for free** on **Hugging Face Spaces (CPU)**.
The app uses:
- **CrewAI** to orchestrate 3 agents (Researcher, Analyst, Strategist).
- A **local LLM** via `llama-cpp-python` (no API keys).
- **DuckDuckGo Search** (no key) for public web intel.
- A local **CRM Excel** + mock **usage/tickets CSVs** to analyze account health.

## Oneâ€‘click Deploy (Hugging Face Spaces)
1. Create a new **Space** â†’ **SDK: Streamlit** â†’ Name it e.g. `customer-intel-agent`.
2. Upload this entire repo (drag-drop or push via Git).
3. Choose **Hardware: CPU Basic** (free).
4. Wait for the first build. The app will download a small GGUF model on first run.
5. Open the Space. Enter a company name and click **Run analysis**.

> First generation may take ~10â€“20s on CPU. Subsequent runs are faster due to model caching.

## Local Run (optional)
```bash
python -m venv .venv && source .venv/bin/activate        # Windows: .venv\Scripts\activate
pip install -r requirements.txt
streamlit run app.py
```

## Repo Layout
```
customer-intel-agent/
â”œâ”€ app.py
â”œâ”€ crew_setup.py
â”œâ”€ local_llm.py
â”œâ”€ tools/
â”‚  â”œâ”€ crm_tool.py
â”‚  â”œâ”€ account_data_tool.py
â”‚  â””â”€ web_search_tool.py
â”œâ”€ data/
â”‚  â”œâ”€ crm.xlsx
â”‚  â”œâ”€ usage.csv
â”‚  â””â”€ tickets.csv
â”œâ”€ prompts/
â”‚  â”œâ”€ researcher.md
â”‚  â”œâ”€ analyst.md
â”‚  â””â”€ strategist.md
â”œâ”€ scripts/
â”‚  â””â”€ make_sample_data.py
â”œâ”€ requirements.txt
â”œâ”€ huggingface.yaml
â””â”€ README_SPACE.md
```

## Troubleshooting (HF Spaces)
- If `llama-cpp-python` build fails on Space: restart the Space; the prebuilt wheel is usually picked.
- If downloads fail due to timeouts, click **Restart** from the Space UI; the model is small but the Hub sometimes throttles.
- You can switch to an even smaller GGUF (1â€“2B) in `local_llm.py` for snappier CPU inference.

## License
MIT (for the demo code).
